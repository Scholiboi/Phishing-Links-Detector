{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UIJ595djMOi9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iDTvefeXMdxt"
      },
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "segmented_url_path = '../Generation/segmented_url.csv'\n",
        "segmented_url_data = pd.read_csv(segmented_url_path)\n",
        "\n",
        "# Prepare domain data for fallback\n",
        "domain_data = segmented_url_data.dropna(subset=[\"subdomain\", \"sld\"])\n",
        "domain_data = domain_data.apply(lambda row: f\"{row['subdomain']}.{row['sld']}\", axis=1).tolist()\n",
        "\n",
        "# Extract components for Markov models\n",
        "subdomains = segmented_url_data['subdomain'].dropna().astype(str).tolist()\n",
        "slds = segmented_url_data['sld'].dropna().astype(str).tolist()\n",
        "\n",
        "# Markov chain configuration\n",
        "MARKOV_ORDER = 10  # Higher order for better pattern recognition\n",
        "MIN_LENGTH = 3    # Minimum length for generated components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YMRqxVK7MpPK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_markov_chain(strings, order=3):\n",
        "    \"\"\"Build a Markov chain model from a list of strings\"\"\"\n",
        "    model = defaultdict(lambda: defaultdict(int))\n",
        "    for s in strings:\n",
        "        padded = '^' * order + s + '$'\n",
        "        for i in range(len(padded) - order):\n",
        "            current_state = padded[i:i+order]\n",
        "            next_char = padded[i+order]\n",
        "            model[current_state][next_char] += 1\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XeTXfh_KMzCJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_component(model, order=3, max_length=25):\n",
        "    \"\"\"Generate a new component using the Markov chain\"\"\"\n",
        "    state = '^' * order\n",
        "    result = []\n",
        "    while True:\n",
        "        next_char = random.choices(\n",
        "            list(model[state].keys()),\n",
        "            weights=list(model[state].values())\n",
        "        )[0] if model[state] else None\n",
        "\n",
        "        if not next_char or next_char == '$' or len(result) >= max_length:\n",
        "            break\n",
        "\n",
        "        result.append(next_char)\n",
        "        state = state[1:] + next_char\n",
        "\n",
        "    generated = ''.join(result)\n",
        "    return generated if len(generated) >= MIN_LENGTH else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D478WuDpM1FR"
      },
      "outputs": [],
      "source": [
        "subdomain_chain = build_markov_chain(subdomains, MARKOV_ORDER)\n",
        "sld_chain = build_markov_chain(slds, MARKOV_ORDER)\n",
        "\n",
        "def generate_domain():\n",
        "    \"\"\"Generate a domain name using Markov chains\"\"\"\n",
        "    # Attempt Markov generation\n",
        "    subdomain = generate_component(subdomain_chain, MARKOV_ORDER)\n",
        "    sld = generate_component(sld_chain, MARKOV_ORDER)\n",
        "\n",
        "    # Fallback to dataset if generation fails\n",
        "    if not subdomain or not sld:\n",
        "        fallback = random.choice(domain_data).split('.', 1)\n",
        "        return f\"{fallback[0]}.{fallback[1]}\"\n",
        "\n",
        "    return f\"{subdomain}.{sld}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1vCZ4KXpM3yP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_url():\n",
        "    \"\"\"Generate a complete URL with Markov-generated domain\"\"\"\n",
        "    protocol = random.choice([\"http\", \"https\"])\n",
        "    domain = generate_domain()\n",
        "    subdomain, sld = domain.split(\".\", 1)\n",
        "\n",
        "    # URL components\n",
        "    tld = random.choice(['com', 'org', 'net', 'io', 'gov', 'edu', 'xyz', 'info'])\n",
        "    port = f\":{random.choice([80, 443, 8080])}\" if random.random() > 0.8 else \"\"\n",
        "\n",
        "    # Path components\n",
        "    path_parts = []\n",
        "    for _ in range(random.randint(0, 3)):\n",
        "        path_parts.append(random.choice(['home', 'about', 'products', 'services', 'contact',\n",
        "                                       'api', 'data', 'user', 'profile', 'search']))\n",
        "    path = '/' + '/'.join(path_parts) if path_parts else '/'\n",
        "\n",
        "    # Query parameters\n",
        "    query = \"\"\n",
        "    if random.random() > 0.6:\n",
        "        params = [f\"{k}={random.randint(1000,9999)}\"\n",
        "                for k in random.sample(['id', 'ref', 'session', 'page'], random.randint(1, 3))]\n",
        "        query = \"?\" + \"&\".join(params)\n",
        "\n",
        "    # Fragment\n",
        "    fragment = \"#\" + random.choice(['section', 'top', 'content', 'main']) if random.random() > 0.7 else \"\"\n",
        "\n",
        "    return f\"{protocol}://{subdomain}.{sld}.{tld}{port}{path}{query}{fragment}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uus08XCPMvch",
        "outputId": "d209681b-01d8-4425-8226-af37d168c69c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully generated 2000 URLs: ../Generation/synthetic_urls_markov.csv\n"
          ]
        }
      ],
      "source": [
        "# Generate and save URLs\n",
        "num_urls_to_generate = 2000\n",
        "synthetic_urls = [generate_url() for _ in range(num_urls_to_generate)]\n",
        "\n",
        "output_path = '../Generation/synthetic_urls_markov.csv'\n",
        "pd.DataFrame(synthetic_urls, columns=['url']).to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Successfully generated {num_urls_to_generate} URLs: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS4cAxZPECDf",
        "outputId": "e183c451-b84c-4e13-8987-2d13ab0f6e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 2000 fully data-driven URLs\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import tldextract\n",
        "\n",
        "class DataDrivenURLGenerator:\n",
        "    def __init__(self, data_path, markov_order=3):\n",
        "        self.markov_order = markov_order\n",
        "        self.data = self._load_and_parse_data(data_path)\n",
        "        self._build_models()\n",
        "\n",
        "    def _load_and_parse_data(self, path):\n",
        "        df = pd.read_csv(path)\n",
        "\n",
        "        if 'url' in df.columns:\n",
        "            def parse_url(url):\n",
        "                parsed = urlparse(url)\n",
        "                ext = tldextract.extract(url)\n",
        "                return {\n",
        "                    'protocol': parsed.scheme or 'https',\n",
        "                    'subdomain': ext.subdomain,\n",
        "                    'sld': ext.domain,\n",
        "                    'tld': ext.suffix,\n",
        "                    'port': parsed.port,\n",
        "                    'path': parsed.path,\n",
        "                    'query': parsed.query,\n",
        "                    'fragment': parsed.fragment\n",
        "                }\n",
        "            url_components = df['url'].apply(parse_url).apply(pd.Series)\n",
        "            df = pd.concat([df, url_components], axis=1)\n",
        "\n",
        "        return df.dropna(subset=['sld']).fillna('')\n",
        "\n",
        "    def _build_models(self):\n",
        "        # Protocol model\n",
        "        self.protocols = self._calculate_frequencies(self.data['protocol'])\n",
        "\n",
        "        # Domain models\n",
        "        self.subdomain_chain = self._build_markov_chain(\n",
        "            self.data['subdomain'].astype(str),\n",
        "            self.markov_order\n",
        "        )\n",
        "        self.sld_chain = self._build_markov_chain(\n",
        "            self.data['sld'].astype(str),\n",
        "            self.markov_order\n",
        "        )\n",
        "\n",
        "        # TLD model\n",
        "        self.tlds = self._calculate_frequencies(self.data['tld'])\n",
        "\n",
        "        # Port model\n",
        "        self.ports = self._calculate_frequencies(\n",
        "            self.data['port'].astype(str).replace('', 'none')\n",
        "        )\n",
        "\n",
        "        # Path model\n",
        "        path_segments = self.data['path'].str.split('/').explode().replace('', None).dropna()\n",
        "        self.path_chain = self._build_markov_chain(path_segments, self.markov_order)\n",
        "        self.path_depth = self._calculate_depth_distribution(\n",
        "            self.data['path'].str.split('/').apply(lambda x: len([s for s in x if s])))\n",
        "\n",
        "        # Query model\n",
        "        self.query_params = self._build_query_model()\n",
        "\n",
        "        # Fragment model\n",
        "        self.fragments = self._calculate_frequencies(\n",
        "            self.data['fragment'].replace('', None).dropna()\n",
        "        )\n",
        "\n",
        "    def _build_markov_chain(self, strings, order):\n",
        "        chain = defaultdict(lambda: defaultdict(int))\n",
        "        for s in strings:\n",
        "            padded = '^' * order + s + '$'\n",
        "            for i in range(len(padded) - order):\n",
        "                current = padded[i:i+order]\n",
        "                next_char = padded[i+order]\n",
        "                chain[current][next_char] += 1\n",
        "        return chain\n",
        "\n",
        "    def _calculate_frequencies(self, series):\n",
        "        counts = series.value_counts()\n",
        "        return {\n",
        "            'items': counts.index.tolist(),\n",
        "            'weights': counts.values.tolist(),\n",
        "            'most_common': counts.idxmax() if not counts.empty else ''\n",
        "        }\n",
        "\n",
        "    def _calculate_depth_distribution(self, series):\n",
        "        depth_counts = series.value_counts().sort_index()\n",
        "        return {\n",
        "            'depths': depth_counts.index.tolist(),\n",
        "            'weights': depth_counts.values.tolist()\n",
        "        }\n",
        "\n",
        "    def _build_query_model(self):\n",
        "        param_counts = defaultdict(int)\n",
        "        value_models = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "\n",
        "        for query in self.data['query']:\n",
        "            if not query:\n",
        "                continue\n",
        "            for param, values in parse_qs(query).items():\n",
        "                param_counts[param] += 1\n",
        "                for value in values:\n",
        "                    padded = '^' + value + '$'\n",
        "                    for i in range(len(padded) - 1):\n",
        "                        current = padded[i]\n",
        "                        next_char = padded[i+1]\n",
        "                        value_models[param][current][next_char] += 1\n",
        "\n",
        "        return {\n",
        "            'params': dict(param_counts),\n",
        "            'values': dict(value_models)\n",
        "        }\n",
        "\n",
        "    def _generate_component(self, chain, max_length=25):\n",
        "        if not chain:\n",
        "            return ''\n",
        "\n",
        "        state = '^' * self.markov_order\n",
        "        result = []\n",
        "        while True:\n",
        "            options = chain.get(state, {})\n",
        "            if not options:\n",
        "                break\n",
        "\n",
        "            next_char = random.choices(\n",
        "                list(options.keys()),\n",
        "                weights=list(options.values())\n",
        "            )[0]\n",
        "\n",
        "            if next_char == '$' or len(result) >= max_length:\n",
        "                break\n",
        "\n",
        "            result.append(next_char)\n",
        "            state = state[1:] + next_char\n",
        "\n",
        "        return ''.join(result) if len(result) >= 2 else ''\n",
        "\n",
        "    def _generate_domain(self):\n",
        "        subdomain = self._generate_component(self.subdomain_chain)\n",
        "        sld = self._generate_component(self.sld_chain)\n",
        "\n",
        "        if not sld:\n",
        "            return random.choice(self.data['sld'].dropna().tolist())\n",
        "\n",
        "        return f\"{subdomain}.{sld}\" if subdomain else sld\n",
        "\n",
        "    def _generate_path(self):\n",
        "        depth = random.choices(\n",
        "            self.path_depth['depths'],\n",
        "            weights=self.path_depth['weights'],\n",
        "            k=1\n",
        "        )[0] if self.path_depth['depths'] else 0\n",
        "\n",
        "        segments = []\n",
        "        for _ in range(depth):\n",
        "            segment = self._generate_component(self.path_chain)\n",
        "            if segment:\n",
        "                segments.append(segment)\n",
        "\n",
        "        return '/' + '/'.join(segments) if segments else ''\n",
        "\n",
        "    def _generate_query(self):\n",
        "        if not self.query_params['params'] or random.random() > 0.6:\n",
        "            return ''\n",
        "\n",
        "        params = random.choices(\n",
        "            list(self.query_params['params'].keys()),\n",
        "            weights=list(self.query_params['params'].values()),\n",
        "            k=random.randint(1, 3)\n",
        "        )\n",
        "\n",
        "        param_strings = []\n",
        "        for param in params:\n",
        "            value_chain = self.query_params['values'].get(param, {})\n",
        "            value = self._generate_component(value_chain, max_length=12)\n",
        "            param_strings.append(f\"{param}={value}\" if value else param)\n",
        "\n",
        "        return '?' + '&'.join(param_strings) if param_strings else ''\n",
        "\n",
        "    def generate_url(self):\n",
        "        protocol = random.choices(\n",
        "            self.protocols['items'],\n",
        "            weights=self.protocols['weights'],\n",
        "            k=1\n",
        "        )[0] if self.protocols['items'] else 'https'\n",
        "\n",
        "        domain = self._generate_domain()\n",
        "        tld = random.choices(\n",
        "            self.tlds['items'],\n",
        "            weights=self.tlds['weights'],\n",
        "            k=1\n",
        "        )[0] if self.tlds['items'] else 'com'\n",
        "\n",
        "        port = ''\n",
        "        if self.ports['items'] and random.random() < (self.ports['weights'][0] / sum(self.ports['weights'])):\n",
        "            port = f\":{random.choices(self.ports['items'], weights=self.ports['weights'])[0]}\"\n",
        "\n",
        "        path = self._generate_path()\n",
        "        query = self._generate_query()\n",
        "\n",
        "        fragment = ''\n",
        "        if self.fragments['items'] and random.random() < 0.3:\n",
        "            fragment = \"#\" + random.choices(\n",
        "                self.fragments['items'],\n",
        "                weights=self.fragments['weights']\n",
        "            )[0]\n",
        "\n",
        "        return f\"{protocol}://{domain}.{tld}{port}{path}{query}{fragment}\"\n",
        "# Usage\n",
        "generator = DataDrivenURLGenerator('../Generation/segmented_url.csv')\n",
        "synthetic_urls = [generator.generate_url() for _ in range(2000)]\n",
        "\n",
        "# Save results\n",
        "pd.DataFrame(synthetic_urls, columns=['url']).to_csv(\n",
        "    './data_driven_urls.csv',\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(synthetic_urls)} fully data-driven URLs\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
